# NICAR-21
An example of automated news archiving on a schedule. `archive-example.py` contains the scraper, which takes articles from an author page and saves them to the Wayback Machine. Scheduling is handled by GitHub Actions.

# Additional Resources
For those interested in learning more about archiving.

## Data Storage
[U.S. government 3-2-1 rule documentation](https://us-cert.cisa.gov/sites/default/files/publications/data_backup_options.pdf)

Real-time cloud storage sync solutions for [Box](https://www.box.com/resources/downloads), [Dropbox](https://www.dropbox.com/install), and [Google Drive](https://www.google.com/intl/en_ca/drive/download/)

Motherboard's [`mass_archive`](https://github.com/motherboardgithub/mass_archive/blob/master/mass_archive.py) tool

IIPC's [list of archiving tools](https://github.com/iipc/awesome-web-archiving)

## Storing non-text data
[Boss and Broussard, 2017: Challenges of archiving and preserving born-digital news applications](https://journals.sagepub.com/doi/10.1177/0340035216686355)

[Broussard, Archiving Data Journalism](https://datajournalism.com/read/handbook/two/organising-data-journalism/archiving-data-journalism)

[Preserve This Podcast](https://preservethispodcast.org/)

[The Commons: Activists Guide to Archiving Video](https://commonslibrary.org/activists-guide-to-archiving-video/)

## The Internet Archive
[Wayback Machine General Information](https://help.archive.org/hc/en-us/articles/360004716091-Wayback-Machine-General-Information)

[The WARC file format](https://iipc.github.io/warc-specifications/specifications/warc-format/warc-1.0/)

[Donate to the Internet Archive](https://archive.org/donate/)

## Technical Tools
[GitHub Actions documentation](https://docs.github.com/en/actions)

[`Scrapy`](https://scrapy.org/), a Python web scraping framework
